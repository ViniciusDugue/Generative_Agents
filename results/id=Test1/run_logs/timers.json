{
    "name": "root",
    "gauges": {
        "MultipleFoodGatherer.Policy.Entropy.mean": {
            "value": 1.4138480424880981,
            "min": 1.4080703258514404,
            "max": 1.42503821849823,
            "count": 23
        },
        "MultipleFoodGatherer.Policy.Entropy.sum": {
            "value": 70036.375,
            "min": 69507.3515625,
            "max": 72624.9296875,
            "count": 23
        },
        "MultipleFoodGatherer.Step.mean": {
            "value": 1149952.0,
            "min": 49984.0,
            "max": 1149952.0,
            "count": 23
        },
        "MultipleFoodGatherer.Step.sum": {
            "value": 1149952.0,
            "min": 49984.0,
            "max": 1149952.0,
            "count": 23
        },
        "MultipleFoodGatherer.Policy.ExtrinsicBaselineEstimate.mean": {
            "value": 0.12249444425106049,
            "min": -0.13165152072906494,
            "max": 0.15265975892543793,
            "count": 23
        },
        "MultipleFoodGatherer.Policy.ExtrinsicBaselineEstimate.sum": {
            "value": 97.87306213378906,
            "min": -105.18955993652344,
            "max": 122.12272644042969,
            "count": 23
        },
        "MultipleFoodGatherer.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.12249444425106049,
            "min": -0.13165152072906494,
            "max": 0.15265975892543793,
            "count": 23
        },
        "MultipleFoodGatherer.Policy.ExtrinsicValueEstimate.sum": {
            "value": 97.87306213378906,
            "min": -105.18955993652344,
            "max": 122.12272644042969,
            "count": 23
        },
        "MultipleFoodGatherer.FoodScore.mean": {
            "value": 16.5,
            "min": 3.8333333333333335,
            "max": 22.5,
            "count": 23
        },
        "MultipleFoodGatherer.FoodScore.sum": {
            "value": 99.0,
            "min": 23.0,
            "max": 146.0,
            "count": 23
        },
        "MultipleFoodGatherer.Losses.PolicyLoss.mean": {
            "value": 0.024027627577390485,
            "min": 0.02227160718926991,
            "max": 0.026496571186563057,
            "count": 23
        },
        "MultipleFoodGatherer.Losses.PolicyLoss.sum": {
            "value": 0.09611051030956194,
            "min": 0.09027042038929224,
            "max": 0.13248285593281528,
            "count": 23
        },
        "MultipleFoodGatherer.Losses.ValueLoss.mean": {
            "value": 0.010752374759988127,
            "min": 0.0013414112276581309,
            "max": 0.013303386837977804,
            "count": 23
        },
        "MultipleFoodGatherer.Losses.ValueLoss.sum": {
            "value": 0.043009499039952506,
            "min": 0.0053656449106325235,
            "max": 0.06651693418988902,
            "count": 23
        },
        "MultipleFoodGatherer.Losses.BaselineLoss.mean": {
            "value": 0.010752374759988127,
            "min": 0.0013414112276581309,
            "max": 0.013303386837977804,
            "count": 23
        },
        "MultipleFoodGatherer.Losses.BaselineLoss.sum": {
            "value": 0.043009499039952506,
            "min": 0.0053656449106325235,
            "max": 0.06651693418988902,
            "count": 23
        },
        "MultipleFoodGatherer.Policy.LearningRate.mean": {
            "value": 0.00018747843750719997,
            "min": 0.00018747843750719997,
            "max": 0.00029726400091199996,
            "count": 23
        },
        "MultipleFoodGatherer.Policy.LearningRate.sum": {
            "value": 0.0007499137500287999,
            "min": 0.0007499137500287999,
            "max": 0.00143856002048,
            "count": 23
        },
        "MultipleFoodGatherer.Policy.Epsilon.mean": {
            "value": 0.1624928,
            "min": 0.1624928,
            "max": 0.199088,
            "count": 23
        },
        "MultipleFoodGatherer.Policy.Epsilon.sum": {
            "value": 0.6499712,
            "min": 0.6499712,
            "max": 0.9795200000000001,
            "count": 23
        },
        "MultipleFoodGatherer.Policy.Beta.mean": {
            "value": 0.00312839072,
            "min": 0.00312839072,
            "max": 0.004954491199999999,
            "count": 23
        },
        "MultipleFoodGatherer.Policy.Beta.sum": {
            "value": 0.01251356288,
            "min": 0.01251356288,
            "max": 0.023978048000000002,
            "count": 23
        },
        "MultipleFoodGatherer.Environment.EpisodeLength.mean": {
            "value": 999.0,
            "min": 999.0,
            "max": 999.0,
            "count": 23
        },
        "MultipleFoodGatherer.Environment.EpisodeLength.sum": {
            "value": 47952.0,
            "min": 47952.0,
            "max": 71928.0,
            "count": 23
        },
        "MultipleFoodGatherer.Environment.CumulativeReward.mean": {
            "value": 1.2916666666666667,
            "min": 0.16666666666666666,
            "max": 1.6938775510204083,
            "count": 23
        },
        "MultipleFoodGatherer.Environment.CumulativeReward.sum": {
            "value": 62.0,
            "min": 8.0,
            "max": 117.0,
            "count": 23
        },
        "MultipleFoodGatherer.Policy.ExtrinsicReward.mean": {
            "value": 1.2916666666666667,
            "min": 0.16666666666666666,
            "max": 1.6938775510204083,
            "count": 23
        },
        "MultipleFoodGatherer.Policy.ExtrinsicReward.sum": {
            "value": 62.0,
            "min": 8.0,
            "max": 117.0,
            "count": 23
        },
        "MultipleFoodGatherer.Environment.GroupCumulativeReward.mean": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 23
        },
        "MultipleFoodGatherer.Environment.GroupCumulativeReward.sum": {
            "value": 0.0,
            "min": 0.0,
            "max": 0.0,
            "count": 23
        },
        "MultipleFoodGatherer.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 23
        },
        "MultipleFoodGatherer.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 23
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1743069043",
        "python_version": "3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\ViniciusDugue\\Desktop\\Generative_Agents\\venv\\Scripts\\mlagents-learn configuration.yaml --run-id=id=Test1",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "1.13.1+cu117",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1743094826"
    },
    "total": 25782.624356999993,
    "count": 1,
    "self": 0.008136400021612644,
    "children": {
        "run_training.setup": {
            "total": 0.055403899983502924,
            "count": 1,
            "self": 0.055403899983502924
        },
        "TrainerController.start_learning": {
            "total": 25782.56081669999,
            "count": 1,
            "self": 0.9799789064563811,
            "children": {
                "TrainerController._reset_env": {
                    "total": 8.18613440002082,
                    "count": 1,
                    "self": 8.18613440002082
                },
                "TrainerController.advance": {
                    "total": 25772.821503593528,
                    "count": 48067,
                    "self": 0.924774297804106,
                    "children": {
                        "env_step": {
                            "total": 25227.09904479666,
                            "count": 48067,
                            "self": 25089.41275009833,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 136.9988311934867,
                                    "count": 48067,
                                    "self": 3.8634799970313907,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 133.1353511964553,
                                            "count": 48067,
                                            "self": 133.1353511964553
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.6874635048443452,
                                    "count": 48066,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 1574.778391097847,
                                            "count": 48066,
                                            "is_parallel": true,
                                            "self": 768.3321057041758,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.00199709995649755,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 9.959988528862596e-05,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.001897500071208924,
                                                            "count": 8,
                                                            "is_parallel": true,
                                                            "self": 0.001897500071208924
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 806.4442882937146,
                                                    "count": 48066,
                                                    "is_parallel": true,
                                                    "self": 44.834372495359275,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 18.94546279910719,
                                                            "count": 48066,
                                                            "is_parallel": true,
                                                            "self": 18.94546279910719
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 603.0133368991083,
                                                            "count": 48066,
                                                            "is_parallel": true,
                                                            "self": 603.0133368991083
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 139.65111610013992,
                                                            "count": 48066,
                                                            "is_parallel": true,
                                                            "self": 6.998416220070794,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 132.65269988006912,
                                                                    "count": 384528,
                                                                    "is_parallel": true,
                                                                    "self": 132.65269988006912
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 544.7976844990626,
                            "count": 48066,
                            "self": 1.2019206939148717,
                            "children": {
                                "process_trajectory": {
                                    "total": 277.99728100484936,
                                    "count": 48066,
                                    "self": 277.90751850488596,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.08976249996339902,
                                            "count": 1,
                                            "self": 0.08976249996339902
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 265.59848280029837,
                                    "count": 103,
                                    "self": 147.56562330044108,
                                    "children": {
                                        "TorchPOCAOptimizer.update": {
                                            "total": 118.0328594998573,
                                            "count": 3234,
                                            "self": 118.0328594998573
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "TrainerController._save_models": {
                    "total": 0.5731997999828309,
                    "count": 1,
                    "self": 0.09296409995295107,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.4802357000298798,
                            "count": 1,
                            "self": 0.4802357000298798
                        }
                    }
                }
            }
        }
    }
}